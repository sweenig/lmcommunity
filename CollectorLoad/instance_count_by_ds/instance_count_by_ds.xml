<?xml version="1.0" encoding="UTF-8" ?>
<feed  version="1.0" hasPendingRequests="false" >
  <company></company>
  <status>200</status>
  <errmsg>OK</errmsg>
  <interval>0</interval>
    <entry type="predatasource">
        <version>1590085490</version>
        <name>instance_count_by_ds</name>
        <displayedas>Instances by DataSource</displayedas>
        <description>Counts the number of instances a device has, grouped by DataSource</description>
        <collector>batchscript</collector>
        <hasMultiInstances>true</hasMultiInstances>
        <schedule>180</schedule>
        <appliesTo>instance_count_by_ds.id &#38;&#38; instance_count_by_ds.pass &#38;&#38; instance_count_by_ds.account</appliesTo>
        <wildcardauto>true</wildcardauto>
        <wildcardpersist>false</wildcardpersist>
        <wildcardlinuxscript>ad_script</wildcardlinuxscript>
        <wildcardlinuxcmdline>type=&#34;embeded&#34; </wildcardlinuxcmdline>
        <wildcardwinscript>ad_script</wildcardwinscript>
        <wildcardwincmdline>type=&#34;embeded&#34; </wildcardwincmdline>
        <wildcardgroovyscript>//initialize
import javax.crypto.Mac
import javax.crypto.spec.SecretKeySpec
import org.apache.commons.codec.binary.Hex
import groovy.json.JsonSlurper

def generate_headers(id, key, path) {
  try {
    // Create encryption signature for authorization request
    Long epoch_time = System.currentTimeMillis()  // Get current system time (epoch time)
    Mac hmac = Mac.getInstance(&#34;HmacSHA256&#34;)
    hmac.init(new SecretKeySpec(key.getBytes(), &#34;HmacSHA256&#34;))
    signature = Hex.encodeHexString(hmac.doFinal(&#34;GET${epoch_time}${path}&#34;.getBytes())).bytes.encodeBase64()
    // return headers to main function
    return [&#34;Authorization&#34;: &#34;LMv1 $id:$signature:$epoch_time&#34;, &#34;Content-Type&#34;: &#34;application/json&#34;]
  } catch (Exception err) {
    // If error occurred, print the error message
    println(&#34;ERROR: Unable to establish encryption for $path. Attempting next resource...\n${err.message}&#34;)
  }
}

def get_response(resource, parameters, account, headers) {
  try {
    boolean proceed = true  // Boolean used to determine if additional pagination is required
    // Map to store query results for each endpoint.  Contains a list to store actual returned values and a boolean to determine if successful
    Map results = [&#34;response&#34;: [],
             &#34;success&#34; : true]
    add_query_parameters(resource, parameters)
    // Add initial offset and size values to appropriate categories (skips metrics category since it&#39;s stagnate)
    while (proceed) {
      // Used for paginating through all availabe results.  Grabs 1000 at a time and moves offset if another query is required.
      Map query = query_resource(account, parameters, headers)
      // Query each API endpoint for a response (Should receive as Map)
      // If the response was successful (including status and error messages), proceed to printing results
      if (query &#38;&#38; query?.data &#38;&#38; query?.status == 200 &#38;&#38; query?.errmsg?.toUpperCase() == &#34;OK&#34;) {
        if (resource != &#34;metrics&#34;) {
          results.response.addAll(query.data.items)   // Add all the data items found to our results map data list
          if (query?.data?.items?.size() &#60; parameters.details.size) {
            // If we received less than 1000 results
            proceed = false   // There is no need to execute another API query with a shifted offset
          } else {    // Otherwise
            parameters.details.offset += parameters.details.size
            // Shift the offset to start 1000 numbers from current position
          }
        } else {
          results.response = query.data   // Add all the data items found to our results map data list
          proceed = false   // We&#39;ve successfully queried all values.  End while loop
        }
      } else {
        // If response was not successful, print eror message for each category that failed and continue to next endpoint
        // If response error and status can be determined, print them.  Otherwise, use UNKNOWN
        println(&#34;ERROR: Failed to query $resource API Endpoint...\n&#34; +
            &#34;${query?.errmsg?.toUpperCase() ?: &#39;UNKNOWN&#39;} (STATUS: ${query?.status ?: &#39;UNKNOWN&#39;})&#34;)
        results.success = false   // Set success value to false since we failed our API query
        proceed = false   // End while loop because of failure and proceed to next endpoint
      }
    }
    return results  // Return results to main function
  } catch (Exception err) {
    println(&#34;ERROR: Script failed while attempting to query $resource API endpoint...\n${err?.message}&#34;)
  }
}

def add_query_parameters(category, parameters) {
  // Add size and offset field to map (only if collectors or admins category)
  if (category != &#34;metrics&#34;) {
    Map query_details = [&#34;size&#34;  : 1000, &#34;offset&#34;: 0]
    // If there&#39;s already a details key in the details map
    if (parameters.details) {
      parameters.details &#60;&#60; query_details
      // Append the query details information to the pre-existing details map
    } else {  // Otherwise, create a details key and assign it the query details map as a value
      parameters.put(&#34;details&#34;, query_details)
    }
  }
}

def query_resource(account, details, headers) {
  try {
    // Configure request url from account, path, and authorization headers
    String url = &#34;https://${account}.logicmonitor.com/santaba/rest${details.path}?${pack_parameters(details.details)}&#34;
    // Return query response, converted from JSON to usable map
    return new JsonSlurper().parseText(url.toURL().getText(useCaches: true, allowUserInteraction: false, requestProperties: headers))
  } catch (Exception err) { // If error occurred, print the error message
    println(&#34;ERROR: Unable to query ${details.path} for details.\n${err.message}&#34;)
  }
}

def pack_parameters(query_details) { // If additional query details are located in map, include them in url string
  List pairs = []
  query_details?.each { k, v -&#62; pairs.add(&#34;${k}=${v}&#34;)}
  return pairs.join(&#34;&#38;&#34;)
}

//setup
ds_name = &#34;instance_count_by_ds&#34;
Map credentials = [
  &#34;id&#34;   : hostProps.get(&#34;${ds_name}.id&#34;),
  &#34;key&#34;  : hostProps.get(&#34;${ds_name}.pass&#34;),
  &#34;account&#34;: hostProps.get(&#34;${ds_name}.account&#34;)
]

deviceid = hostProps.get(&#34;system.deviceId&#34;)

Map resources = [:]
resources[&#34;instances&#34;] = [&#34;path&#34;: &#34;/device/devices/${deviceid}/instances&#34;, &#34;details&#34;: [&#34;fields&#34;: &#34;name&#34;]]

//gather
if (credentials.account &#38;&#38; credentials.id &#38;&#38; credentials.key) {
  resources.each() { k, v -&#62;
    Map headers = generate_headers(credentials.id, credentials.key, v.path)
    if (headers) {
      Map response = get_response(k, v, credentials.account, headers)
      if (response?.success) {resources[k][&#34;data&#34;] = response.response}
    }
  }
} else {
  println(&#34;&#34;&#34;Device is not configured with the necessary portal credentials to proceed with API queries.
Please ensure that \&#34;${ds_name}.id\&#34;, \&#34;${ds_name}.pass\&#34;, and \&#34;${ds_name}.account\&#34; are set in the collector properties section!
Exiting Program...&#34;&#34;&#34;)
  return 1
}

dscounts = [:]

//transform
resources.instances.data.each(){
  dsname = it.name.tokenize(&#34;-&#34;)[0].replaceAll(&#34; &#34;,&#34;&#34;)
  if (dscounts.containsKey(dsname)) {
    dscounts[dsname] += 1
  } else {
    dscounts[dsname] = 1
  }
}

//output
collect = false
dscounts.each{k,v-&#62;
  if (collect) {
    println(&#34;${k}.count: ${v}&#34;)
  } else {
    println(&#34;${k}##${k}&#34;)
  }
}

return 0
</wildcardgroovyscript>
        <wildcardschedule>60</wildcardschedule>
        <wildcarddisable>false</wildcarddisable>
        <wildcarddeleteinactive>true</wildcarddeleteinactive>
        <agdmethod>none</agdmethod>
        <agdparams></agdparams>
        <group>_WeenigWare</group>
        <tags></tags>
        <technology>requires instance_count_by_ds properties for id, pass, and account containing the API id, API key, and account name, respectively.</technology>
        <adlist><![CDATA[{"agdmethod":"none","method":"ad_script","agdparams":"","id":0,"filters":[],"params":{"type":"embeded","groovyscript":"//initialize\nimport javax.crypto.Mac\nimport javax.crypto.spec.SecretKeySpec\nimport org.apache.commons.codec.binary.Hex\nimport groovy.json.JsonSlurper\n\ndef generate_headers(id, key, path) {\n  try {\n    // Create encryption signature for authorization request\n    Long epoch_time = System.currentTimeMillis()  // Get current system time (epoch time)\n    Mac hmac = Mac.getInstance(\"HmacSHA256\")\n    hmac.init(new SecretKeySpec(key.getBytes(), \"HmacSHA256\"))\n    signature = Hex.encodeHexString(hmac.doFinal(\"GET${epoch_time}${path}\".getBytes())).bytes.encodeBase64()\n    // return headers to main function\n    return [\"Authorization\": \"LMv1 $id:$signature:$epoch_time\", \"Content-Type\": \"application/json\"]\n  } catch (Exception err) {\n    // If error occurred, print the error message\n    println(\"ERROR: Unable to establish encryption for $path. Attempting next resource...\\n${err.message}\")\n  }\n}\n\ndef get_response(resource, parameters, account, headers) {\n  try {\n    boolean proceed = true  // Boolean used to determine if additional pagination is required\n    // Map to store query results for each endpoint.  Contains a list to store actual returned values and a boolean to determine if successful\n    Map results = [\"response\": [],\n             \"success\" : true]\n    add_query_parameters(resource, parameters)\n    // Add initial offset and size values to appropriate categories (skips metrics category since it's stagnate)\n    while (proceed) {\n      // Used for paginating through all availabe results.  Grabs 1000 at a time and moves offset if another query is required.\n      Map query = query_resource(account, parameters, headers)\n      // Query each API endpoint for a response (Should receive as Map)\n      // If the response was successful (including status and error messages), proceed to printing results\n      if (query && query?.data && query?.status == 200 && query?.errmsg?.toUpperCase() == \"OK\") {\n        if (resource != \"metrics\") {\n          results.response.addAll(query.data.items)   // Add all the data items found to our results map data list\n          if (query?.data?.items?.size() < parameters.details.size) {\n            // If we received less than 1000 results\n            proceed = false   // There is no need to execute another API query with a shifted offset\n          } else {    // Otherwise\n            parameters.details.offset += parameters.details.size\n            // Shift the offset to start 1000 numbers from current position\n          }\n        } else {\n          results.response = query.data   // Add all the data items found to our results map data list\n          proceed = false   // We've successfully queried all values.  End while loop\n        }\n      } else {\n        // If response was not successful, print eror message for each category that failed and continue to next endpoint\n        // If response error and status can be determined, print them.  Otherwise, use UNKNOWN\n        println(\"ERROR: Failed to query $resource API Endpoint...\\n\" +\n            \"${query?.errmsg?.toUpperCase() ?: 'UNKNOWN'} (STATUS: ${query?.status ?: 'UNKNOWN'})\")\n        results.success = false   // Set success value to false since we failed our API query\n        proceed = false   // End while loop because of failure and proceed to next endpoint\n      }\n    }\n    return results  // Return results to main function\n  } catch (Exception err) {\n    println(\"ERROR: Script failed while attempting to query $resource API endpoint...\\n${err?.message}\")\n  }\n}\n\ndef add_query_parameters(category, parameters) {\n  // Add size and offset field to map (only if collectors or admins category)\n  if (category != \"metrics\") {\n    Map query_details = [\"size\"  : 1000, \"offset\": 0]\n    // If there's already a details key in the details map\n    if (parameters.details) {\n      parameters.details << query_details\n      // Append the query details information to the pre-existing details map\n    } else {  // Otherwise, create a details key and assign it the query details map as a value\n      parameters.put(\"details\", query_details)\n    }\n  }\n}\n\ndef query_resource(account, details, headers) {\n  try {\n    // Configure request url from account, path, and authorization headers\n    String url = \"https://${account}.logicmonitor.com/santaba/rest${details.path}?${pack_parameters(details.details)}\"\n    // Return query response, converted from JSON to usable map\n    return new JsonSlurper().parseText(url.toURL().getText(useCaches: true, allowUserInteraction: false, requestProperties: headers))\n  } catch (Exception err) { // If error occurred, print the error message\n    println(\"ERROR: Unable to query ${details.path} for details.\\n${err.message}\")\n  }\n}\n\ndef pack_parameters(query_details) { // If additional query details are located in map, include them in url string\n  List pairs = []\n  query_details?.each { k, v -> pairs.add(\"${k}=${v}\")}\n  return pairs.join(\"&\")\n}\n\n//setup\nds_name = \"instance_count_by_ds\"\nMap credentials = [\n  \"id\"   : hostProps.get(\"${ds_name}.id\"),\n  \"key\"  : hostProps.get(\"${ds_name}.pass\"),\n  \"account\": hostProps.get(\"${ds_name}.account\")\n]\n\ndeviceid = hostProps.get(\"system.deviceId\")\n\nMap resources = [:]\nresources[\"instances\"] = [\"path\": \"/device/devices/${deviceid}/instances\", \"details\": [\"fields\": \"name\"]]\n\n//gather\nif (credentials.account && credentials.id && credentials.key) {\n  resources.each() { k, v ->\n    Map headers = generate_headers(credentials.id, credentials.key, v.path)\n    if (headers) {\n      Map response = get_response(k, v, credentials.account, headers)\n      if (response?.success) {resources[k][\"data\"] = response.response}\n    }\n  }\n} else {\n  println(\"\"\"Device is not configured with the necessary portal credentials to proceed with API queries.\nPlease ensure that \\\"${ds_name}.id\\\", \\\"${ds_name}.pass\\\", and \\\"${ds_name}.account\\\" are set in the collector properties section!\nExiting Program...\"\"\")\n  return 1\n}\n\ndscounts = [:]\n\n//transform\nresources.instances.data.each(){\n  dsname = it.name.tokenize(\"-\")[0].replaceAll(\" \",\"\")\n  if (dscounts.containsKey(dsname)) {\n    dscounts[dsname] += 1\n  } else {\n    dscounts[dsname] = 1\n  }\n}\n\n//output\ncollect = false\ndscounts.each{k,v->\n  if (collect) {\n    println(\"${k}.count: ${v}\")\n  } else {\n    println(\"${k}##${k}\")\n  }\n}\n\nreturn 0\n"}}]]></adlist>
        <schemaVersion>2</schemaVersion>
        <dataSourceType>1</dataSourceType>
        <attributes>
        <attribute>
            <name>scripttype</name>
            <value>embed</value>
            <comment></comment>
        </attribute>
        <attribute>
            <name>scriptgroovy</name>
            <value>//initialize
import javax.crypto.Mac
import javax.crypto.spec.SecretKeySpec
import org.apache.commons.codec.binary.Hex
import groovy.json.JsonSlurper

def generate_headers(id, key, path) {
  try {
    // Create encryption signature for authorization request
    Long epoch_time = System.currentTimeMillis()  // Get current system time (epoch time)
    Mac hmac = Mac.getInstance(&#34;HmacSHA256&#34;)
    hmac.init(new SecretKeySpec(key.getBytes(), &#34;HmacSHA256&#34;))
    signature = Hex.encodeHexString(hmac.doFinal(&#34;GET${epoch_time}${path}&#34;.getBytes())).bytes.encodeBase64()
    // return headers to main function
    return [&#34;Authorization&#34;: &#34;LMv1 $id:$signature:$epoch_time&#34;, &#34;Content-Type&#34;: &#34;application/json&#34;]
  } catch (Exception err) {
    // If error occurred, print the error message
    println(&#34;ERROR: Unable to establish encryption for $path. Attempting next resource...\n${err.message}&#34;)
  }
}

def get_response(resource, parameters, account, headers) {
  try {
    boolean proceed = true  // Boolean used to determine if additional pagination is required
    // Map to store query results for each endpoint.  Contains a list to store actual returned values and a boolean to determine if successful
    Map results = [&#34;response&#34;: [],
             &#34;success&#34; : true]
    add_query_parameters(resource, parameters)
    // Add initial offset and size values to appropriate categories (skips metrics category since it&#39;s stagnate)
    while (proceed) {
      // Used for paginating through all availabe results.  Grabs 1000 at a time and moves offset if another query is required.
      Map query = query_resource(account, parameters, headers)
      // Query each API endpoint for a response (Should receive as Map)
      // If the response was successful (including status and error messages), proceed to printing results
      if (query &#38;&#38; query?.data &#38;&#38; query?.status == 200 &#38;&#38; query?.errmsg?.toUpperCase() == &#34;OK&#34;) {
        if (resource != &#34;metrics&#34;) {
          results.response.addAll(query.data.items)   // Add all the data items found to our results map data list
          if (query?.data?.items?.size() &#60; parameters.details.size) {
            // If we received less than 1000 results
            proceed = false   // There is no need to execute another API query with a shifted offset
          } else {    // Otherwise
            parameters.details.offset += parameters.details.size
            // Shift the offset to start 1000 numbers from current position
          }
        } else {
          results.response = query.data   // Add all the data items found to our results map data list
          proceed = false   // We&#39;ve successfully queried all values.  End while loop
        }
      } else {
        // If response was not successful, print eror message for each category that failed and continue to next endpoint
        // If response error and status can be determined, print them.  Otherwise, use UNKNOWN
        println(&#34;ERROR: Failed to query $resource API Endpoint...\n&#34; +
            &#34;${query?.errmsg?.toUpperCase() ?: &#39;UNKNOWN&#39;} (STATUS: ${query?.status ?: &#39;UNKNOWN&#39;})&#34;)
        results.success = false   // Set success value to false since we failed our API query
        proceed = false   // End while loop because of failure and proceed to next endpoint
      }
    }
    return results  // Return results to main function
  } catch (Exception err) {
    println(&#34;ERROR: Script failed while attempting to query $resource API endpoint...\n${err?.message}&#34;)
  }
}

def add_query_parameters(category, parameters) {
  // Add size and offset field to map (only if collectors or admins category)
  if (category != &#34;metrics&#34;) {
    Map query_details = [&#34;size&#34;  : 1000, &#34;offset&#34;: 0]
    // If there&#39;s already a details key in the details map
    if (parameters.details) {
      parameters.details &#60;&#60; query_details
      // Append the query details information to the pre-existing details map
    } else {  // Otherwise, create a details key and assign it the query details map as a value
      parameters.put(&#34;details&#34;, query_details)
    }
  }
}

def query_resource(account, details, headers) {
  try {
    // Configure request url from account, path, and authorization headers
    String url = &#34;https://${account}.logicmonitor.com/santaba/rest${details.path}?${pack_parameters(details.details)}&#34;
    // Return query response, converted from JSON to usable map
    return new JsonSlurper().parseText(url.toURL().getText(useCaches: true, allowUserInteraction: false, requestProperties: headers))
  } catch (Exception err) { // If error occurred, print the error message
    println(&#34;ERROR: Unable to query ${details.path} for details.\n${err.message}&#34;)
  }
}

def pack_parameters(query_details) { // If additional query details are located in map, include them in url string
  List pairs = []
  query_details?.each { k, v -&#62; pairs.add(&#34;${k}=${v}&#34;)}
  return pairs.join(&#34;&#38;&#34;)
}

//setup
ds_name = &#34;instance_count_by_ds&#34;
Map credentials = [
  &#34;id&#34;   : hostProps.get(&#34;${ds_name}.id&#34;),
  &#34;key&#34;  : hostProps.get(&#34;${ds_name}.pass&#34;),
  &#34;account&#34;: hostProps.get(&#34;${ds_name}.account&#34;)
]

deviceid = hostProps.get(&#34;system.deviceId&#34;)

Map resources = [:]
resources[&#34;instances&#34;] = [&#34;path&#34;: &#34;/device/devices/${deviceid}/instances&#34;, &#34;details&#34;: [&#34;fields&#34;: &#34;name&#34;]]

//gather
if (credentials.account &#38;&#38; credentials.id &#38;&#38; credentials.key) {
  resources.each() { k, v -&#62;
    Map headers = generate_headers(credentials.id, credentials.key, v.path)
    if (headers) {
      Map response = get_response(k, v, credentials.account, headers)
      if (response?.success) {resources[k][&#34;data&#34;] = response.response}
    }
  }
} else {
  println(&#34;&#34;&#34;Device is not configured with the necessary portal credentials to proceed with API queries.
Please ensure that \&#34;${ds_name}.id\&#34;, \&#34;${ds_name}.pass\&#34;, and \&#34;${ds_name}.account\&#34; are set in the collector properties section!
Exiting Program...&#34;&#34;&#34;)
  return 1
}

dscounts = [:]

//transform
resources.instances.data.each(){
  dsname = it.name.tokenize(&#34;-&#34;)[0].replaceAll(&#34; &#34;,&#34;&#34;)
  if (dscounts.containsKey(dsname)) {
    dscounts[dsname] += 1
  } else {
    dscounts[dsname] = 1
  }
}

//output
collect = true
dscounts.each{k,v-&#62;
  if (collect) {
    println(&#34;${k}.count: ${v}&#34;)
  } else {
    println(&#34;${k}##${k}&#34;)
  }
}

return 0</value>
            <comment></comment>
        </attribute>
        <attribute>
            <name>windowsscript</name>
            <value></value>
            <comment></comment>
        </attribute>
        <attribute>
            <name>linuxscript</name>
            <value></value>
            <comment></comment>
        </attribute>
        <attribute>
            <name>windowscmdline</name>
            <value></value>
            <comment></comment>
        </attribute>
        <attribute>
            <name>linuxcmdline</name>
            <value></value>
            <comment></comment>
        </attribute>
        </attributes>
        <datapoints>
        <datapoint>
            <name>count</name>
            <dataType>7</dataType>
            <type>2</type>
            <postprocessormethod>namevalue</postprocessormethod>
            <postprocessorparam>##WILDVALUE##.count</postprocessorparam>
            <usevalue>output</usevalue>
            <alertexpr></alertexpr>
            <alertmissing>1</alertmissing>
            <alertsubject></alertsubject>
            <alertbody></alertbody>
            <enableanomalyalertsuppression></enableanomalyalertsuppression>
            <adadvsettingenabled>true</adadvsettingenabled>
            <warnadadvsetting></warnadadvsetting>
            <erroradadvsetting></erroradadvsetting>
            <criticaladadvsetting></criticaladadvsetting>
            <description></description>
            <maxvalue></maxvalue>
            <minvalue></minvalue>
            <userparam1></userparam1>
            <userparam2></userparam2>
            <userparam3></userparam3>
            <iscomposite>false</iscomposite>
            <rpn></rpn>
            <alertTransitionIval>0</alertTransitionIval>
            <alertClearTransitionIval>0</alertClearTransitionIval>
        </datapoint>
        </datapoints>
        <graphs>
        <graph>
            <name>DataSource Weight</name>
            <title>DataSource Weight</title>
            <verticallabel>instance count</verticallabel>
            <rigid>false</rigid>
            <maxvalue>NaN</maxvalue>
            <minvalue>0.0</minvalue>
            <displayprio>1</displayprio>
            <timescale>1day</timescale>
            <base1024>false</base1024>
            <graphdatapoints>
        <graphdatapoint>
            <name>count</name>
            <datapointname>count</datapointname>
            <cf>1</cf>
        </graphdatapoint>
            </graphdatapoints>
            <graphvirtualdatapoints>
            </graphvirtualdatapoints>
            <graphdatas>
            <graphdata>
                <type>1</type>
                <legend>Instance Count</legend>
                <color>silver</color>
                <datapointname>count</datapointname>
                <isvirtualdatapoint>false</isvirtualdatapoint>
            </graphdata>
            </graphdatas>
        </graph>
        </graphs>
        <overviewgraphs>
        <overviewgraph>
            <name>DataSource Weight</name>
            <title>DataSource Weight</title>
            <verticallabel>instance count</verticallabel>
            <rigid>false</rigid>
            <maxvalue>NaN</maxvalue>
            <minvalue>0.0</minvalue>
            <displayprio>1</displayprio>
            <timescale>1day</timescale>
            <base1024>false</base1024>
            <aggregated>false</aggregated>
            <datapoints>
        <overviewgraphdatapoint>
            <name>count</name>
            <datapointname>count</datapointname>
            <cf>1</cf>
            <aggregateMethod>sum</aggregateMethod>
        </overviewgraphdatapoint>
            </datapoints>
            <virtualdatapoints>
            </virtualdatapoints>
            <lines>
            <overviewgraphline>
                <type>3</type>
                <legend>##INSTANCE##</legend>
                <datapointname>count</datapointname>
                <isvirtualdatapoint>false</isvirtualdatapoint>
                <color>silver</color>
            </overviewgraphline>
            </lines>
        </overviewgraph>
        </overviewgraphs>
        <scripts>
        </scripts>
    </entry>
</feed>
